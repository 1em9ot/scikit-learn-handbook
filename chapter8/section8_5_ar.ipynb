{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c81bebc9",
   "metadata": {},
   "source": [
    "# AR(1)プロセスからランダムウォーク、そしてMCMCへ\n",
    "\n",
    "このノートブックでは、時系列解析の基礎となる **AR(1)プロセス**（1次自己回帰モデル）を出発点とし、その係数 $\\phi$ が 1 に近づくにつれて現れる **ランダムウォーク（酔歩）**、そしてそのランダムウォークを「探索」に応用した **メトロポリス・ヘイスティングス法 (MCMC)** までの流れを、数式とインタラクティブなシミュレーションで地続きに解説します。\n",
    "\n",
    "---\n",
    "\n",
    "## 1. AR(1) プロセスとは\n",
    "\n",
    "AR(1) プロセス（AutoRegressive process of order 1）は、**「現在の値が、1つ前の値とノイズで決まる」** 最もシンプルな時系列モデルです。\n",
    "\n",
    "$$\n",
    "y_t = \\phi y_{t-1} + \\varepsilon_t, \\quad \\varepsilon_t \\sim N(0, \\sigma^2)\n",
    "$$\n",
    "\n",
    "ここで、\n",
    "- $y_t$: 時刻 $t$ における値\n",
    "- $\\phi$: **自己回帰係数** (Autoregressive coefficient)\n",
    "- $\\varepsilon_t$: ホワイトノイズ（平均0、分散$\\sigma^2$の正規分布に従う）\n",
    "\n",
    "この $\\phi$ の値によって、時系列の挙動（**定常性**）が劇的に変化します。\n",
    "\n",
    "- **$|\\phi| < 1$ (定常)**: 平均 0 の周りを振動し、長期的には安定します。\n",
    "- **$|\\phi| = 1$ (単位根・ランダムウォーク)**: **非定常**。平均へ回帰せず、どこまでも彷徨います。\n",
    "- **$|\\phi| > 1$ (発散)**: 指数関数的に値が大きくなります。\n",
    "\n",
    "### 自己相関 (ACF) と 偏自己相関 (PACF)\n",
    "ARモデルの特徴は、**コレログラム**（自己相関図）に現れます。\n",
    "\n",
    "- **自己相関関数 (ACF)**: 時間差（ラグ）$k$ だけ離れたデータ間の相関。\n",
    "    - AR(1) の場合、ACFは $\\phi^k$ で減衰します（$\\phi=0.8$なら $0.8, 0.64, 0.512...$）。\n",
    "- **偏自己相関関数 (PACF)**: 間の時点の影響を取り除いた直接的な相関。\n",
    "    - AR(1) の場合、**ラグ1 ( $\\phi$ ) だけが有意な値を持ち、ラグ2以降はゼロになります**（これがARモデルの識別基準です）。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bec13c",
   "metadata": {},
   "source": [
    "### 【実験】 $\\phi$ を変えて挙動を確認しよう\n",
    "\n",
    "スライダーで $\\phi$ を動かして、以下の点を確認してください。\n",
    "1. **$\\phi = 0.5$**: ACFは速やかに減衰し、PACFはラグ1のみ立つ。\n",
    "2. **$\\phi = 0.9$**: ACFの減衰が遅くなる（記憶が長く残る）。\n",
    "3. **$\\phi = 1.0$**: **ランダムウォーク**。ACFはほとんど減衰せず、1付近に留まる（これを「単位根」と呼ぶ）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7c0000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import japanize_matplotlib\n",
    "\n",
    "def simulate_ar1_interactive(phi=0.8, sigma=1.0, T=200):\n",
    "    # シミュレーション\n",
    "    np.random.seed(42)\n",
    "    y = np.zeros(T)\n",
    "    epsilon = np.random.normal(0, sigma, T)\n",
    "    \n",
    "    # 初期値\n",
    "    if abs(phi) < 1:\n",
    "        y[0] = epsilon[0] / np.sqrt(1 - phi**2)\n",
    "    else:\n",
    "        y[0] = 0\n",
    "        \n",
    "    for t in range(1, T):\n",
    "        y[t] = phi * y[t-1] + epsilon[t]\n",
    "        \n",
    "    # プロット作成\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # 1. 時系列プロット\n",
    "    ax1 = fig.add_subplot(1, 3, 1)\n",
    "    ax1.plot(y)\n",
    "    ax1.set_title(rf\"時系列 $y_t = {phi} y_{{t-1}} + \\varepsilon$\")\n",
    "    ax1.set_xlabel(\"時刻 $t$\")\n",
    "    ax1.set_ylabel(\"$y_t$\")\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    if abs(phi) >= 1:\n",
    "        ax1.text(0.05, 0.9, \"非定常 (Non-Stationary)\", transform=ax1.transAxes, color=\"red\", fontweight=\"bold\")\n",
    "    else:\n",
    "        ax1.text(0.05, 0.9, \"定常 (Stationary)\", transform=ax1.transAxes, color=\"blue\", fontweight=\"bold\")\n",
    "\n",
    "    # 2. ACF (自己相関)\n",
    "    ax2 = fig.add_subplot(1, 3, 2)\n",
    "    plot_acf(y, lags=20, ax=ax2, title=\"自己相関 (ACF)\")\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. PACF (偏自己相関)\n",
    "    ax3 = fig.add_subplot(1, 3, 3)\n",
    "    try:\n",
    "        plot_pacf(y, lags=20, ax=ax3, title=\"偏自己相関 (PACF)\", method='ywm')\n",
    "    except:\n",
    "        ax3.text(0.5, 0.5, \"計算エラー (非定常)\", ha='center')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# インタラクティブ・ウィジェット\n",
    "w_phi = widgets.FloatSlider(value=0.8, min=-1.1, max=1.1, step=0.1, description=r'係数 $\\phi$:', continuous_update=False)\n",
    "display(widgets.interactive(simulate_ar1_interactive, phi=w_phi, sigma=widgets.fixed(1.0), T=widgets.fixed(200)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b07b662",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. 定常から非定常へ：ランダムウォーク（酔歩）\n",
    "\n",
    "$\\phi = 1$ のとき、式は以下のようになります。\n",
    "\n",
    "$$\n",
    "y_t = y_{t-1} + \\varepsilon_t\n",
    "$$\n",
    "\n",
    "これは、**「昨日の位置からランダムに一歩進んだ場所が今日の位置」** というモデルです。これを **ランダムウォーク（酔歩）** と呼びます。またの名を「イカ（Squid）」の遊泳とも喩えられます（予測不可能な動き）。\n",
    "\n",
    "### なぜこれが重要なのか？\n",
    "ランダムウォークは、**「分散が時間とともに増大する」** という性質を持ちます。\n",
    "$$\n",
    "\\mathrm{Var}(y_t) = t \\sigma^2\n",
    "$$\n",
    "つまり、時間が経てば経つほど、**どこにいるか予測がつかなくなる（＝探索範囲が広がる）** ということです。\n",
    "\n",
    "統計学（特にベイズ統計）では、この「どこへ行くかわからない＝空間を広く探索できる」という性質を**逆に利用**します。それが次に紹介する **MCMC（マルコフ連鎖モンテカルロ法）** です。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c633bb01",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. ランダムウォークの応用：メトロポリス・ヘイスティングス法\n",
    "\n",
    "確率分布 $p(x)$ からサンプリングを行いたいとき、その分布が複雑だと直接サンプリングできません。そこで、**ランダムウォークを使って分布の「山」を探索**します。\n",
    "\n",
    "### アルゴリズムの直感\n",
    "1. **今いる場所** を $x_t$ とします。\n",
    "2. 次の候補 $x_{new}$ を、**ランダムウォーク** で決めます。\n",
    "   $$ x_{new} = x_t + \\varepsilon, \\quad \\varepsilon \\sim N(0, \\sigma^2) $$\n",
    "   （これはまさに、$\\phi=1$ の AR(1) プロセスの1ステップです！）\n",
    "3. $x_{new}$ が $x_t$ よりも「確率が高い（山頂に近い）」場所なら、必ず移動します。\n",
    "4. 「確率が低い（麓の方）」場所なら、コイン投げをして、運が良ければ移動、悪ければ留まります。\n",
    "\n",
    "こうすることで、ランダムウォーク（酔っ払い）は、**確率が高い場所ほど頻繁に訪れる**ようになります。その足跡（Trace）を集めると、目的の確率分布に従うサンプルが得られます。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目標分布の可視化\n",
    "まずはサンプリングしたい **目標分布** $\\pi(x)$ を図で確認します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "# 目標分布: 標準正規分布 N(0, 1)\n",
    "def target_pdf(x):\n",
    "    return norm.pdf(x, loc=0, scale=1)\n",
    "\n",
    "x = np.linspace(-4, 4, 400)\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(x, target_pdf(x), color='crimson', lw=3, label=r'$\\pi(x)$（目標分布）')\n",
    "plt.title('目標分布 $\\pi(x)$', fontsize=13)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('密度')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提案分布の可視化（ランダムウォーク）\n",
    "メトロポリス・ヘイスティングス法では、現在位置 $x_t$ から\n",
    "$$x_{new} = x_t + ε,\\quad ε \\sim N(0, σ^2)$$\n",
    "という **提案分布** を使います。ここでは $x_t=1.5$ と仮定して可視化します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_x = 1.5\n",
    "step_width = 1.0\n",
    "\n",
    "proposal_x = np.linspace(-4, 6, 400)\n",
    "proposal_pdf = norm.pdf(proposal_x, loc=current_x, scale=step_width)\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(proposal_x, proposal_pdf, color='navy', lw=3, label='提案分布 $q(x\\'|x_t)$')\n",
    "plt.axvline(current_x, color='orange', ls='--', lw=2, label=r'現在位置 $x_t$')\n",
    "plt.title('提案分布（ランダムウォーク）', fontsize=13)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('密度')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 採択確率の形（途中計算の可視化）\n",
    "採択確率は\n",
    "$$\n",
    "\\alpha(x_{new}, x_t) = \\min\\left(1, \\frac{\\pi(x_{new})}{\\pi(x_t)}\\right)\n",
    "$$\n",
    "で与えられます。$x_t$ を固定したとき、$x_{new}$ に対する形を描いてみます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_x = 1.5\n",
    "x_new = np.linspace(-4, 4, 400)\n",
    "ratio = target_pdf(x_new) / target_pdf(current_x)\n",
    "accept_prob = np.minimum(1.0, ratio)\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(x_new, accept_prob, color='purple', lw=3)\n",
    "plt.axvline(current_x, color='orange', ls='--', lw=2, label=r'現在位置 $x_t$')\n",
    "plt.title('採択確率 $\\alpha(x_{new}, x_t)$', fontsize=13)\n",
    "plt.xlabel('提案値 $x_{new}$')\n",
    "plt.ylabel('採択確率')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d0871",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_metropolis_hastings(n_iter=5000, step_width=1.0):\n",
    "    # 目標分布: 標準正規分布 N(0, 1) とあえて少しズラした N(3, 0.5) の混合分布を想定してみる\n",
    "    # シンプルにするため、ここでは標準正規分布 N(0, 1) を目標とする\n",
    "    np.random.seed(123)\n",
    "    current_x = 10.0  # 初期値（あえて遠くからスタート）\n",
    "    samples = []\n",
    "    trace = []\n",
    "    \n",
    "    # 提案分布としてランダムウォークを使用\n",
    "    # x_new = 1.0 * x_old + epsilon  (つまり phi=1 の AR(1))\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        # 1. 提案 (Random Walk Step)\n",
    "        epsilon = np.random.normal(0, step_width)\n",
    "        proposal_x = current_x + epsilon\n",
    "        \n",
    "        # 2. 採択確率 (Metropolis基準)\n",
    "        # p(x_new) / p(x_old)\n",
    "        ratio = target_pdf(proposal_x) / target_pdf(current_x)\n",
    "        acceptance_prob = min(1.0, ratio)\n",
    "        \n",
    "        # 3. 判定\n",
    "        if np.random.rand() < acceptance_prob:\n",
    "            current_x = proposal_x  # 採択（移動）\n",
    "        else:\n",
    "            current_x = current_x   # 棄却（滞留）\n",
    "            \n",
    "        trace.append(current_x)\n",
    "        if i > 500: # バーンイン（初期の影響を除く）\n",
    "            samples.append(current_x)\n",
    "            \n",
    "    # 可視化\n",
    "    fig = plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    # トレースプロット（時系列）\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.plot(trace, lw=0.8, color='navy', alpha=0.7)\n",
    "    # 生文字列でエスケープを回避\n",
    "    ax1.set_title(rf\"MCMCの軌跡 (トレースプロット)\\nランダムウォーク $\\phi=1$ による探索\", fontsize=14)\n",
    "    ax1.set_xlabel(\"Step $t$\")\n",
    "    ax1.set_ylabel(\"$x_t$\")\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.text(0.05, 0.9, \"探索的挙動 (探索)\", transform=ax1.transAxes, color=\"green\", fontweight=\"bold\")\n",
    "\n",
    "    # ヒストグラム（分布）\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    ax2.hist(samples, bins=50, density=True, color='skyblue', alpha=0.7, label=\"MCMCサンプル\")\n",
    "    x = np.linspace(-4, 4, 100)\n",
    "    ax2.plot(x, target_pdf(x), 'r-', lw=3, label=\"目標分布\")\n",
    "    ax2.set_title(\"サンプリング結果の分布\", fontsize=14)\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 実行\n",
    "run_metropolis_hastings()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a15277b",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## （付録）平均の分散に関する理論的考察\n",
    "\n",
    "まず平均を\n",
    "$$\n",
    "\\bar{y}_T = \\frac{1}{T}\\sum_{t=1}^T y_t\n",
    "$$\n",
    "と置くと、自己共分散 $\\gamma_h=\\mathrm{Cov}(y_t,y_{t-h})$ を用いて\n",
    "$$\n",
    "\\mathrm{Var}(\\bar{y}_T)= \\frac{1}{T^2}\\sum_{t=1}^T\\sum_{s=1}^T\\gamma_{|t-s|}\n",
    "$$\n",
    "となります。AR(1)では $\\gamma_h=\\sigma_u^2\\phi^{|h|}$ なので、二重和を整理すると\n",
    "$$\n",
    "\\mathrm{Var}(\\bar{y}_T)= \\frac{1}{T^2}\\Big(T\\gamma_0 + 2\\sum_{h=1}^{T-1}(T-h)\\gamma_h\\Big)\n",
    "$$\n",
    "$$\n",
    "= \\frac{1}{T^2}\\Big(T\\sigma_u^2 + 2\\sum_{h=1}^{T-1}(T-h)\\sigma_u^2\\phi^h\\Big)\n",
    "$$\n",
    "となり、相関がある（$\\phi \\neq 0$）と、独立な場合（iid）に比べて分散が変化することがわかります。\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}