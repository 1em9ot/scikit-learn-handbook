{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMAモデルのインタラクティブ・シミュレーション\n",
    "\n",
    "本ノートブックでは、**ARIMA(p, d, q) モデル** の挙動をインタラクティブに観察します。\n",
    "\n",
    "自己回帰項 (AR)、和分項 (I: 差分)、移動平均項 (MA) のパラメータを変更することで、\n",
    "生成される時系列データや、自己相関関数 (ACF)、偏自己相関関数 (PACF) がどのように変化するかを確認してください。\n",
    "\n",
    "## 観察のポイント\n",
    "1. **AR(p) の挙動**:\n",
    "   - AR係数（phi）を大きくすると、過去の値への依存が強まります。\n",
    "   - ACFは徐々に減衰し、PACFはラグ $p$ でカットオフ（切断）します。\n",
    "2. **MA(q) の挙動**:\n",
    "   - MA係数（theta）を変更すると、過去の誤差の影響が変わります。\n",
    "   - PACFは徐々に減衰し、ACFはラグ $q$ でカットオフします。\n",
    "3. **非定常性 (d)**:\n",
    "   - 差分階数 $d$ を1以上にすると、データはトレンドを持ち、非定常になります（ランダムウォークなど）。\n",
    "   - $d=0$ の場合、データは平均の周りを振動する定常過程になります（係数が定常条件を満たす場合）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# 日本語フォントの設定\n",
    "import matplotlib.font_manager as fm\n",
    "font_path = '../fonts/ipaexg.ttf'\n",
    "fm.fontManager.addfont(font_path)\n",
    "plt.rcParams['font.family'] = 'IPAexGothic'\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_arima_interactive(ar1, ar2, ma1, ma2, d, n_samples=200):\n",
    "    # AR係数とMA係数の設定\n",
    "    # statsmodelsでは、AR項は左辺に移項した形 (1 - phi*L)y = ... なので符号を反転させる必要がある\n",
    "    # しかし、ユーザーの直感的には y_t = phi * y_{t-1} が自然なので、\n",
    "    # ここでは入力された正の係数を statsmodels 用に負に変換する。\n",
    "    ar_params = np.array([1, -ar1, -ar2])\n",
    "    ma_params = np.array([1, ma1, ma2])\n",
    "    \n",
    "    # ARMAプロセスの生成\n",
    "    # ar1, ar2 が大きすぎると非定常になる可能性があるが、ここではそのまま通す\n",
    "    try:\n",
    "        process = ArmaProcess(ar_params, ma_params)\n",
    "        sample = process.generate_sample(nsample=n_samples)\n",
    "        \n",
    "        # 差分 (Integration) の適用\n",
    "        if d > 0:\n",
    "            # 累積和をとることで積分過程にする（簡易的な実装）\n",
    "            for _ in range(d):\n",
    "                sample = np.cumsum(sample)\n",
    "                \n",
    "        # プロット\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "        \n",
    "        # 1. 時系列プロット\n",
    "        axes[0].plot(sample)\n",
    "        axes[0].set_title(f\"時系列データ (AR=[{ar1}, {ar2}], MA=[{ma1}, {ma2}], d={d})\")\n",
    "        axes[0].set_xlabel(\"Time\")\n",
    "        axes[0].set_ylabel(\"Value\")\n",
    "        axes[0].grid(True)\n",
    "        \n",
    "        # 定常性のチェック（AR部分の根が単位円外にあるか）\n",
    "        if not process.isstationary and d == 0:\n",
    "             axes[0].text(0.05, 0.9, \"※非定常 (AR係数が大)\", transform=axes[0].transAxes, color=\"red\", fontweight=\"bold\")\n",
    "\n",
    "        # 2. 自己相関 (ACF)\n",
    "        # 非定常データでACFを計算すると減衰が遅いが、ここではそのまま表示する\n",
    "        plot_acf(sample, lags=20, ax=axes[1], title=\"自己相関 (ACF)\")\n",
    "        axes[1].grid(True)\n",
    "\n",
    "        # 3. 偏自己相関 (PACF)\n",
    "        try:\n",
    "            plot_pacf(sample, lags=20, ax=axes[2], title=\"偏自己相関 (PACF)\", method='ywm')\n",
    "        except:\n",
    "            axes[2].text(0.5, 0.5, \"PACF計算エラー\\n(定常性なし)\", ha='center')\n",
    "        axes[2].grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# ウィジェットの作成\n",
    "style = {'description_width': 'initial'}\n",
    "\n",
    "w_ar1 = widgets.FloatSlider(value=0.5, min=-1.5, max=1.5, step=0.1, description='AR(1) phi1:', style=style)\n",
    "w_ar2 = widgets.FloatSlider(value=0.0, min=-1.0, max=1.0, step=0.1, description='AR(2) phi2:', style=style)\n",
    "w_ma1 = widgets.FloatSlider(value=0.0, min=-1.5, max=1.5, step=0.1, description='MA(1) theta1:', style=style)\n",
    "w_ma2 = widgets.FloatSlider(value=0.0, min=-1.0, max=1.0, step=0.1, description='MA(2) theta2:', style=style)\n",
    "w_d = widgets.IntSlider(value=0, min=0, max=2, description='差分 d:', style=style)\n",
    "\n",
    "ui = widgets.VBox([\n",
    "    widgets.HBox([w_ar1, w_ar2]),\n",
    "    widgets.HBox([w_ma1, w_ma2]),\n",
    "    w_d\n",
    "])\n",
    "\n",
    "out = widgets.interactive_output(plot_arima_interactive, \n",
    "                                 {'ar1': w_ar1, 'ar2': w_ar2, \n",
    "                                  'ma1': w_ma1, 'ma2': w_ma2, \n",
    "                                  'd': w_d})\n",
    "\n",
    "display(ui, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AR(1)モデルと回帰分析の視覚的理解\n",
    "\n",
    "AR(1)モデル $y_t = \\phi y_{t-1} + \\epsilon_t$ は、**「現在の値 $y_t$ を、1つ前の値 $y_{t-1}$ で回帰する（説明する）」** モデルです。\n",
    "これを視覚的に確認するために、時系列データのプロットと同時に、横軸に $y_{t-1}$、縦軸に $y_t$ をとった**散布図（Lag Plot）**を表示します。\n",
    "\n",
    "AR係数 $\\phi$ を変化させると、散布図上の点の分布の「傾き」や相関の強さがどのように変わるか観察してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def plot_ar1_regression(phi, n_samples=200):\n",
    "    # AR(1)データの生成\n",
    "    # y_t = phi * y_{t-1} + epsilon\n",
    "    # statsmodelsのArmaProcessを使うと符号反転が必要だが、\n",
    "    # ここではシンプルに直接生成する（初期値の影響などを排除しやすい）\n",
    "    np.random.seed(42)\n",
    "    epsilon = np.random.normal(0, 1, n_samples)\n",
    "    y = np.zeros(n_samples)\n",
    "    \n",
    "    # 定常分布からのサンプリングを初期値とする（定常の場合）\n",
    "    if abs(phi) < 1:\n",
    "        y[0] = np.random.normal(0, 1 / np.sqrt(1 - phi**2))\n",
    "    else:\n",
    "        y[0] = 0\n",
    "\n",
    "    for t in range(1, n_samples):\n",
    "        y[t] = phi * y[t-1] + epsilon[t]\n",
    "        \n",
    "    # ラグデータの作成\n",
    "    y_current = y[1:]\n",
    "    y_lag1 = y[:-1]\n",
    "    \n",
    "    # 線形回帰（確認用）\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(y_lag1.reshape(-1, 1), y_current)\n",
    "    y_pred = lr.predict(y_lag1.reshape(-1, 1))\n",
    "    \n",
    "    # プロット\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # 1. 時系列プロット\n",
    "    axes[0].plot(y)\n",
    "    axes[0].set_title(f\"AR(1) 時系列 (phi={phi})\")\n",
    "    axes[0].set_xlabel(\"Time\")\n",
    "    axes[0].set_ylabel(\"Value\")\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # 2. 散布図 (Lag Plot)\n",
    "    axes[1].scatter(y_lag1, y_current, alpha=0.5, label=\"Data\")\n",
    "    axes[1].plot(y_lag1, y_pred, color='red', linewidth=2, label=f\"Regression Line (Slope={lr.coef_[0]:.2f})\")\n",
    "    axes[1].set_title(f\"散布図: $y_{{t-1}}$ vs $y_t$\")\n",
    "    axes[1].set_xlabel(\"$y_{t-1}$ (1期前の値)\")\n",
    "    axes[1].set_ylabel(\"$y_t$ (現在の値)\")\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    # 補助線\n",
    "    min_val = min(y.min(), y_lag1.min())\n",
    "    max_val = max(y.max(), y_lag1.max())\n",
    "    axes[1].plot([min_val, max_val], [min_val, max_val], color='gray', linestyle='--', alpha=0.5, label=\"y=x\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ウィジェット\n",
    "w_phi_reg = widgets.FloatSlider(value=0.7, min=-1.1, max=1.1, step=0.1, description='phi:', style=style)\n",
    "\n",
    "display(widgets.interactive(plot_ar1_regression, phi=w_phi_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任意次数のAR(p)モデルとPACFの関係\n",
    "\n",
    "ここでは、より高次の AR($p$) モデルにおける、偏自己相関関数 (PACF) の挙動を確認します。\n",
    "理論的には、AR($p$) 過程の PACF は、ラグ $p$ までは有意な値を持ち、ラグ $p+1$ 以降はゼロになります（カットオフ）。\n",
    "\n",
    "以下のスライダーで次数 $p$ を変更し、PACFがどのように変化するかを観察してください。\n",
    "\n",
    "※ 係数は、定常性を満たすように内部で自動的に設定されます（減衰パターンなど）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ar_p_interactive(p, n_samples=500):\n",
    "    # 係数の自動設定（簡易的）\n",
    "    # phi_k = 0.6 * (0.8)^(k-1) * (-1)^(k-1) みたいな減衰振動パターンを与える\n",
    "    # これにより、そこそこ定常性を保ちつつ、高次まで係数がある状態を作る\n",
    "    \n",
    "    if p == 0:\n",
    "        ar_coeffs = []\n",
    "    else:\n",
    "        # 少し減衰させつつ、符号を交互にするなどして特徴を出す\n",
    "        # 係数の絶対値の和が1を超えると非定常になりやすいので調整\n",
    "        # ここでは単調減衰パターンを採用\n",
    "        signs = np.ones(p)\n",
    "        # signs[1::2] = -1 # 符号交互の場合\n",
    "        \n",
    "        # 減衰係数\n",
    "        decay = 0.6\n",
    "        ar_coeffs = [decay**(i+1) * signs[i] for i in range(p)]\n",
    "        \n",
    "        # 係数の総和チェック（簡易的な定常性確保）\n",
    "        if np.sum(np.abs(ar_coeffs)) >= 1.0:\n",
    "             ar_coeffs = np.array(ar_coeffs) / (np.sum(np.abs(ar_coeffs)) + 0.1)\n",
    "\n",
    "    # statsmodels用のARパラメータ (1, -phi1, -phi2, ...)\n",
    "    ar_params = np.r_[1, -np.array(ar_coeffs)]\n",
    "    ma_params = np.array([1])\n",
    "    \n",
    "    try:\n",
    "        process = ArmaProcess(ar_params, ma_params)\n",
    "        sample = process.generate_sample(nsample=n_samples)\n",
    "        \n",
    "        # 係数の表示\n",
    "        print(f\"設定されたAR係数 (phi_1 ... phi_{p}):\")\n",
    "        print([f\"{c:.3f}\" for c in ar_coeffs])\n",
    "        \n",
    "        if not process.isstationary:\n",
    "            print(\"※ 注意: 生成されたプロセスは非定常の可能性があります。\")\n",
    "\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "        \n",
    "        # 1. 時系列\n",
    "        axes[0].plot(sample)\n",
    "        axes[0].set_title(f\"AR({p}) 時系列\")\n",
    "        axes[0].set_xlabel(\"Time\")\n",
    "        axes[0].grid(True)\n",
    "\n",
    "        # 2. ACF\n",
    "        plot_acf(sample, lags=20, ax=axes[1], title=\"自己相関 (ACF)\")\n",
    "        axes[1].grid(True)\n",
    "\n",
    "        # 3. PACF\n",
    "        plot_pacf(sample, lags=20, ax=axes[2], title=\"偏自己相関 (PACF)\", method='ywm')\n",
    "        # カットオフの期待位置を表示\n",
    "        if p > 0:\n",
    "            axes[2].axvline(x=p, color='red', linestyle='--', alpha=0.5, label=f'Lag {p}')\n",
    "            axes[2].legend()\n",
    "        axes[2].grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# ウィジェット\n",
    "w_p = widgets.IntSlider(value=1, min=0, max=10, step=1, description='次数 p:', style=style)\n",
    "\n",
    "display(widgets.interactive(plot_ar_p_interactive, p=w_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2df3e8",
   "metadata": {},
   "source": [
    "## ARモデルとMAモデルの比較（ACF vs PACF）\n",
    "\n",
    "ARモデルとMAモデル（移動平均モデル）は、**ACFとPACFのどちらが「切断（Cut off）」するか**という点で対照的な性質を持ちます。\n",
    "\n",
    "- **AR(1)**: PACFがラグ1で切断、ACFは減衰\n",
    "- **MA(1)**: ACFがラグ1で切断、PACFは減衰\n",
    "\n",
    "以下のインタラクティブ・グラフで、モデルを切り替えてその対照性を確認してください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2780a079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_arma_comparison(model_type, param1):\n",
    "    n_samples = 500\n",
    "    \n",
    "    if model_type == 'AR(1)':\n",
    "        # AR(1): (1 - phi*L)y = e  => ar_params = [1, -phi]\n",
    "        phi = param1\n",
    "        ar_params = np.array([1, -phi])\n",
    "        ma_params = np.array([1])\n",
    "        title_text = rf\"AR(1) with $\\phi={phi:.1f}$\"\n",
    "        desc_text = \"AR(1): ACFは減衰 (Tail off), **PACFはラグ1で切断 (Cut off)**\"\n",
    "        \n",
    "    elif model_type == 'MA(1)':\n",
    "        # MA(1): y = (1 + theta*L)e => ma_params = [1, theta]\n",
    "        theta = param1\n",
    "        ar_params = np.array([1])\n",
    "        ma_params = np.array([1, theta])\n",
    "        title_text = rf\"MA(1) with $\\theta={theta:.1f}$\"\n",
    "        desc_text = \"MA(1): **ACFはラグ1で切断 (Cut off)**, PACFは減衰 (Tail off)\"\n",
    "        \n",
    "    # Generate\n",
    "    try:\n",
    "        process = ArmaProcess(ar_params, ma_params)\n",
    "        if not process.isstationary and model_type == 'AR(1)':\n",
    "             # ARが非定常の場合\n",
    "             pass\n",
    "             \n",
    "        sample = process.generate_sample(nsample=n_samples)\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "        \n",
    "        # ACF\n",
    "        plot_acf(sample, lags=20, ax=axes[0], title=\"自己相関 (ACF)\")\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        if model_type == 'MA(1)' and abs(param1) < 1:\n",
    "             axes[0].axvline(x=1, color='red', linestyle='--', alpha=0.5, label='Cut off')\n",
    "             axes[0].legend()\n",
    "\n",
    "        # PACF\n",
    "        plot_pacf(sample, lags=20, ax=axes[1], title=\"偏自己相関 (PACF)\", method='ywm')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        if model_type == 'AR(1)' and abs(param1) < 1:\n",
    "             axes[1].axvline(x=1, color='red', linestyle='--', alpha=0.5, label='Cut off')\n",
    "             axes[1].legend()\n",
    "             \n",
    "        plt.suptitle(title_text + \"\\n\" + desc_text, fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        display(fig)\n",
    "        plt.close(fig)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Widget\n",
    "style = {'description_width': 'initial'}\n",
    "w_type = widgets.ToggleButtons(options=['AR(1)', 'MA(1)'], description='Model:', value='AR(1)', style=style)\n",
    "w_param = widgets.FloatSlider(value=0.7, min=-0.9, max=0.9, step=0.1, description='Coeff:', style=style)\n",
    "\n",
    "display(widgets.interactive(plot_arma_comparison, model_type=w_type, param1=w_param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058064ca",
   "metadata": {},
   "source": [
    "# コラム：ARIMAモデルとは\n",
    "\n",
    "*(夜間、街の明かりに照らされた近代的な都市で、オンライン設備を見ている若いビジネスウーマン)*\n",
    "\n",
    "### 共同執筆者\n",
    "**Joshua Noble** (Data Scientist)\n",
    "\n",
    "## ARIMAモデルの概要\n",
    "ARIMAは自己回帰和分移動平均（AutoRegressive Integrated Moving Average）の略称で、時系列分析および時系列で将来生じ得る値を予測するための手法です。\n",
    "\n",
    "自己回帰モデリングと移動平均モデリングは、時系列データを予測するための2つの異なるアプローチです。ARIMAはこれら2つのアプローチを統合しているため、この名前が付けられています。予測は、時系列の過去の動作を使用して、その時系列の1つ以上の将来の値を予測する機械学習の一分野です。小さな店でアイスクリームを買うことを想像してみてください。天候の温暖化に伴い、アイスクリームの売上が着実に増加していることをご存じであれば、おそらく来週の注文は、この数週間の注文よりも少し増えるはずだと予測できるでしょう。どの程度大きくなるかは、今週の売上が前週の売上とどれだけ異なるかによって決まります。比較する過去がなければ未来を予測することはできないため、過去の時系列データはARIMAばかりではなく、すべての予測手法や時系列分析手法にとって非常に重要です。\n",
    "\n",
    "ARIMA は、時系列予測に最も広く使用されているアプローチの1つであり、作業する時系列データのタイプに応じて異なる2つの方法で使用できます。最初のケースでは、時系列データの季節性を考慮する必要のない非季節性ARIMAモデルを作成しました。過去のデータのパターンに基づいて未来を予測します。2番目のケースでは、時系列に影響する規則的なサイクルである季節性を考慮しています。これらのサイクルは日次、週次、月次のいずれかに指定でき、将来の値を予測するために使用できる時系列の過去データのパターンを定義するのに役立ちます。データサイエンスの多くと同様に、予測の基礎となるのは、モデルをトレーニングするための優れた時系列データを持つことです。時系列は、変数を等間隔で測定する順序付けされた一連の値です。この等間隔の時間間隔要件のため、時間要素を含むすべてのデータセットが実際には時系列データであるとは限らないことを覚えておくことが重要です。\n",
    "\n",
    "## ボックス・ジェンキンス法\n",
    "1970年、統計学者のジョージ・ボックスとグウィリム・ジェンキンスは、あらゆる種類の時系列モデルを適合させるために、ボックス・ジェンキンス法として知られるようになった方法を提案しました。このアプローチは、時系列を生成したプロセスが定常である場合、モデルを使用して近似できるという仮定から始まります。これは、次の4つのステップで構成されています。\n",
    "\n",
    "1. **識別**：時系列が定常であるかどうかを評価し、定常でない場合は、定常とするために必要な差分の数を評価します。次に、診断プロットで使用する差分データを生成します。自己相関および部分自己相関からデータのARMAモデルのパラメーターを特定します。\n",
    "2. **推定**：データを使ってモデルのパラメーター（係数）をトレーニングします。\n",
    "3. **診断チェック**：利用可能なデータとの関連で適合モデルを評価し、モデルが改善される可能性のある領域をチェックします。特に、過剰適合のチェックや残差の計算が含まれます。\n",
    "4. **予測**：モデルができたら、そのモデルを使用して値の予測を開始できます。\n",
    "\n",
    "モデルがデータに正しく適合していることを確認したら、ARIMAによる予測を開始する準備が整います。これらの各ステップを詳しく見ていきます。\n",
    "\n",
    "## 時系列データの特徴\n",
    "時系列は定常時系列か非定常時系列のいずれの場合もあります。定常時系列には、時間の経過とともに一定の統計的特性があります。つまり、平均、分散、自己相関などの統計は、データによって変化しないという意味です。ARIMAなどのほとんどの統計的予測手法は、時系列が1つ以上の変換を通じてほぼ定常にできるという仮定に基づいています。定常時系列は、統計的性質が将来も過去とほぼ同じであることを単純に予測できるため、予測が比較的容易です。非固定データの操作は可能ですが、ARIMAのようなアプローチでは困難です。\n",
    "\n",
    "時系列データの別の主な特徴は、データにトレンドが存在するかどうかです。例えば、過去50年間に食料品店で販売されていた基本食料品の価格は、インフレによって価格が上昇するため、トレンドを示すことになります。トレンドを含むデータの予測は、トレンドによってデータ内の他のパターンが不明瞭になるため、難しい場合があります。データに安定したトレンド・ラインがあり、それが一貫して回帰する場合、それはトレンド定常である可能性があります。この場合、モデルを当てはめる前に、トレンド・ラインを当てはめ、データからトレンドを差し引くだけで、トレンドを取り除くことができます。データがトレンド定常でない場合は、差分定常である可能性があり、その場合は差分化によってトレンドを取り除くことができます。差分化を行う最も簡単な方法は、各値から前の値を引いて、時系列データにどれだけの変化があるかを測定することです。例えば、$Y_t$が期間$t$における時系列Yの値である場合、期間$t$におけるYの最初の差は$Y_t - Y_{t-1}$に等しくなります。\n",
    "\n",
    "こちらは、非定常時系列のプロットです。それは明らかな上昇傾向があり、季節性を示しています。\n",
    "\n",
    "*(徐々に増加する時系列を示す時系列グラフ)*\n",
    "\n",
    "ここでの季節性は、通常の12か月サイクルです。これは、時系列を12単位ずつ差分して対処すると1990年4月と1989年4月を区別できます。12単位の遅延を伴う差分を時系列に適用すると、より定常な時系列が得られます。この時系列の差異はまだ変化していますが、ARIMAモデルはこの時系列に適合し、それを使用した予測を行うことができます。\n",
    "\n",
    "*(前のデータを差分で示し、増加傾向を除外した時系列グラフ)*\n",
    "\n",
    "例えば、周期的な振る舞いはあるがトレンドや季節性のない時系列も定常的です。系列を観察する際にサイクルの長さが一定でない限り、サイクルのピークと谷がどこで発生するのかを知ることはできません。一般に、定常的な時系列には、長期的には予測可能なパターンはありません。時系列データを折れ線グラフにプロットすると、一定の分散があり、大きなスパイクや減少がないため、ほぼ水平方向に見えます。\n",
    "\n",
    "## 自己相関\n",
    "自己相関を計算することで、時系列が過去の値とどの程度相関しているかを知ることができます。自己相関を計算することで、データがランダム性を示しているかどうか、ある観測値がすぐ隣の観測値とどの程度関連しているかについての質問に答えることができます。これにより、どのようなモデルがデータを最もよく表しているかがわかります。自己相関は、ラグ単位までの点間の相関関係を確認するためにプロットされることがよくあります。\n",
    "\n",
    "自己相関における各ラグ$k$は、次のように定義されます。\n",
    "\n",
    "$$\n",
    "r_k = \\frac{\\sum_{t=k+1}^T (y_t - \\bar{y})(y_{t-k} - \\bar{y})}{\\sum_{t=1}^T (y_t - \\bar{y})^2}\n",
    "$$\n",
    "\n",
    "$r$は自己相関の遅れ、$T$は時系列の長さ、$y$は時系列の値を表します。自己相関係数は自己相関関数（ACF）を構成します。\n",
    "\n",
    "ACFでは、相関係数はx軸にあり、遅れの数（遅れ順序と呼ばれる）はy軸に示されます。自己相関プロットは、statsmodelsライブラリーの`plot_acf`を使用してPythonで作成でき、`acf`関数を使用してRで作成できます。\n",
    "\n",
    "*(自己相関関数のプロット)*\n",
    "\n",
    "このACFプロットでは、12の時間単位のラグで差分された時系列のラグは、ゼロラグ自体と完全に相関しています。最初のラグは負、2番目のラグはわずかに正、3番目のラグは負のようになります。12番目のラグはそれ自体と強く相関していることに気付くでしょう。月次データを見ていたので、これは理にかなっています。自己相関は時系列全体でほぼ同じサイクルを維持しており、時系列にはまだ大きな季節性が含まれていることを示しています。ACFプロットは、このデータに最も適合するARIMAモデルのパラメーターを推測するのにも役立ちます。\n",
    "\n",
    "\n",
    "\n",
    "### 自己相関の直感的理解\n",
    "想像してみてください。ある日の売上や気温、株価などの時系列データがあるとします。「今日の売上」と「昨日の売上」は似たような傾向があるかもしれません。もっと前の「1週間前の売上」も、何らかの関係を持っているかもしれません。自己相関とは、この「時刻差（ラグ：lag）＝k」のときに、いまの値と1つ前、2つ前……というずらし方での相関を数値で表したものです。\n",
    "\n",
    "自己相関を調べると、「データがどのくらい過去の値に影響されているか」が見えます。\n",
    "- 時系列がランダムすぎて自己相関がほとんどない場合：過去の値から未来を予測しづらい\n",
    "- 自己相関が強く残っている場合：少し前のデータから未来を予想できそう\n",
    "といった判断に使えます。\n",
    "\n",
    "## 部分自己相関関数（PACF）\n",
    "時系列データにARIMAモデルを使用する準備におけるもう1つの重要なプロットは、部分自己相関関数です。ACFプロットは、$y_t$と$y_{t-k}$の間の関係を、$k$のさまざまな値について示します。$y_t$と$y_{t-1}$が相関している場合、$y_{t-1}$と$y_{t-2}$も相関します。しかし、$y_{t-2}$に含まれる新しい情報が$y_t$の予測に使われるのではなく、むしろ$y_{t-1}$と$y_{t-2}$の両方が関連しているために、$y_t$と$y_{t-2}$が相関している可能性もあります。この問題を克服するためには、偏自己相関を使用して、多くのラグ観測値を取り除くことができます。これらは、ラグ1から$k$の影響を取り除いた後の$y_t$と$y_{t-k}$の関係を測定します。それで、最初の偏自己相関は最初の自己相関と同じです。それは、除去すべき何かがないからです。各部分的な自己相関は、自己回帰モデルの最後の係数として推定できます。\n",
    "\n",
    "RやPython、その他のプログラミング言語やライブラリーで作業していても、PACFを計算し、簡単に検査できるPACFプロットを作成する方法があります。自己相関プロットは、pythonではstatsmodelsライブラリーの`plot_pacf`を使って作成でき、Rでは`pacf`関数を使って作成できます。\n",
    "\n",
    "*(偏自己相関関数のプロット)*\n",
    "\n",
    "このPACFは、上記のACFプロットと同じデータを使用しています。PACFプロットは、ACFプロットのように0ではなく1から始まり、前年の同じ月と相関する1.0の遅れまで強い相関を示します。その最初の1年を過ぎると、ラグの数が増えるにつれて自己相関の量が減少していきます。年ごとに変動する月次データを見ていたので、これは理にかなっています。\n",
    "\n",
    "\n",
    "\n",
    "### 偏自己相関の「偏」とは？\n",
    "偏自己相関は、自己相関のうち、間にある他の時点の影響を取り除いたうえで、どれくらい相関があるかを見るものです。\n",
    "たとえば lag=3 の自己相関を見るとき、直接「3つ前のデータ」と現在のデータを比べていますが、そこには「1つ前」「2つ前」のデータの影響も含まれているかもしれません。偏自己相関は、その中間にある影響（ラグ1・ラグ2の影響）をいったん取り除いたうえで、本当に「3つ前のデータ」と「現在のデータ」だけの純粋な相関を測ります。\n",
    "\n",
    "### ARモデルとMAモデルの見分け方\n",
    "ACFとPACFのプロットの形状は、ARIMAモデルの次数（p, q）を決定する重要な手がかりになります。\n",
    "\n",
    "- **AR(p) モデル（自己回帰モデル）の場合**:\n",
    "    - **PACF**がラグ $p$ までは有意で、ラグ $p+1$ 以降は突然ゼロ付近になります（カットオフ）。\n",
    "    - ACFは徐々に減衰します。\n",
    "- **MA(q) モデル（移動平均モデル）の場合**:\n",
    "    - **ACF**がラグ $q$ までは有意で、ラグ $q+1$ 以降は突然ゼロ付近になります（カットオフ）。\n",
    "    - PACFは徐々に減衰します。\n",
    "\n",
    "つまり、ACFとPACFのどちらが「スパッと切れる（カットオフする）」かを見比べることで、ARモデルかMAモデルかの当たりをつけることができます。\n",
    "\n",
    "### 観点の棚卸し（AR/MA/ARIMAの識別）\n",
    "\n",
    "| モデル | 観点1: 自己相関 (ACF) | 観点2: 偏自己相関 (PACF) |\n",
    "|---|---|---|\n",
    "| **AR(p) 自己回帰** | 徐々に減衰 (Tail off) | **ラグpで切断 (Cut off)** |\n",
    "| **MA(q) 移動平均** | **ラグqで切断 (Cut off)** | 徐々に減衰 (Tail off) |\n",
    "| **ARMA / ARIMA** | 徐々に減衰 | 徐々に減衰 |\n",
    "\n",
    "\n",
    "## 自己回帰と移動平均\n",
    "その名前が示すように、ARIMAという頭字語では、渡されたパラメーターに応じて、自己回帰モデルと移動平均モデルを単一のモデルに統合します。時系列全体を通じて変化をモデリングするこれら2つの方法は関連していますが、いくつかの大きな違いがあります。自己回帰モデルでは、変数の過去値の線形結合を使用して予測します。自己回帰という用語は、変数自体に対する回帰であることを示します。この手法は、過去の値を回帰のインプットとして使用する方法が線形回帰モデルと似ています。自己回帰は次のように定義されます。\n",
    "\n",
    "$$\n",
    "y_t = c + \\phi_1 y_{t-1} + \\phi_2 y_{t-2} + \\dots + \\phi_p y_{t-p} + \\varepsilon_t\n",
    "$$\n",
    "\n",
    "ここでは、$\\varepsilon_t$はホワイトノイズです。これは重回帰に似ていますが、予測変数として$y_t$の遅延値を使用します。これをAR(p)モデル、つまりp次の自己回帰モデルと呼びます。\n",
    "\n",
    "一方、移動平均モデルは、回帰で予測変数の過去の値を使用するのではなく、過去の予測誤差を使用します。移動平均は、ウィンドウ内の$k$個の値を単純に平均化し、ここで、$k$は移動平均ウィンドウのサイズであり、このウィンドウを進めます。予測値は実際の値を使用して評価され、時系列の各ステップにおける誤差が特定されます。移動平均は次のように定義されます。\n",
    "\n",
    "$$\n",
    "y_t = c + \\varepsilon_t + \\theta_1 \\varepsilon_{t-1} + \\theta_2 \\varepsilon_{t-2} + \\dots + \\theta_q \\varepsilon_{t-q}\n",
    "$$\n",
    "\n",
    "$\\varepsilon_t$ はホワイトノイズです。これをMA(q)モデル、つまりq次の移動平均モデルと呼びます。もちろん、 $\\varepsilon_t$の値は観測しないので、通常の意味での回帰ではありません。$y_t$の各値は、過去いくつかの予測誤差の重み付けされた移動平均と考えることができることに注意してください。\n",
    "\n",
    "通常、ARIMAモデルでは、自己回帰項（AR）項または移動平均項（MA）のいずれかを使用します。ACFプロットとPACFプロットは、これらの用語のうちどれが最も適切かを判断するためによく使用されます。\n",
    "\n",
    "## ARIMAモデルの指定\n",
    "時系列を定常化し、自己相関の性質が判別されると、ARIMAモデルを適合させることが可能になります。ARIMAモデルには、通常、$p$、$d$、$q$と呼ばれる3つの主要なパラメーターがあります。\n",
    "\n",
    "- **p**：ARIMAの自己回帰部分の次数\n",
    "- **d**：関係する差分の程度\n",
    "- **q**：移動平均部分の次数\n",
    "\n",
    "これらは通常、ARIMA(p, d, q)の順序で書かれます。多くのプログラミング言語やパッケージは、分析する時系列とこれら3つのパラメータを使用して呼び出すことができるARIMA関数を提供しています。ほとんどの場合、データはトレーニング・セットとテスト・セットに分割され、トレーニング後にモデルの精度をテストできます。通常、時間プロットを見だけで、データに最も適切なpとqの値を知ることはできません。ただし、ACFおよびPACFプロットを使用してpとqの適切な値を決定できることが多いため、これらのプロットはARIMAを扱う上で重要な用語です。\n",
    "\n",
    "モデルでAR用語を使用する大まかな基準は次のとおりです。\n",
    "\n",
    "- ACFプロットは自己相関がゼロに向かって減少していることを示す\n",
    "- PACFプロットはゼロに向かって急速に途切れる\n",
    "- 定常系列のACFはLag - 1で正を示す\n",
    "\n",
    "モデルでMAの用語を使用する状況のおおよその基準は、次の場合です。\n",
    "\n",
    "- ラグ-1で負に自己相関\n",
    "- 数回の遅れで急激に低下するACF\n",
    "- PACFが突然ではなく徐々に減少\n",
    "\n",
    "遭遇する可能性のある従来のARIMAモデル・タイプがいくつかあります。\n",
    "\n",
    "- **ARIMA (1,0,0) = 1次自己回帰モデル**: 系列が定常で自己相関関係にある場合、おそらくそれ自体の以前の値の倍数に定数を加えたものとして予測できます。今日からのアイスクリームの売上だけを使って明日のアイスクリームの売上を直接予測できるとしたら、それは一次自己回帰モデルです。\n",
    "- **ARIMA(0,1,0) = ランダム・ウォーク**: 時系列が定常でない場合、最も単純なモデルはランダム・ウォーク・モデルです。ランダム・ウォークは、シーケンス内の次の値がシーケンス内の前の値の修正であるため、乱数のリストとは異なります。これは、よくある、株価の差異値のモデル化方法です。\n",
    "- **ARIMA(1,1,0) = 差分一次自己回帰モデル**: ランダム・ウォーク・モデルのエラーが自己相関している場合、予測方程式に従属変数の1つのラグを追加することで、つまり、Yの最初の差分を1期間ラグしたそれ自体に回帰することで、問題を解決できる可能性があります。\n",
    "- **定数なしのARIMA(0,1,1) = 単純な指数平滑化モデル**: これは、季節性やトレンドのない時系列データに使用されます。過去の観測からの影響度（0～1の間の係数値で示される）を制御する単一の平滑化パラメーターが必要です。この手法では、1に近い値はモデルが過去の観測値にほとんど注意を払うことを意味し、小さい値は予測中により多くの履歴を考慮することを意味します。\n",
    "- **定数付きARIMA(0,1,1) = 単純な指数平滑化成長モデル**: これは、単純な指数平滑化と同じですが、時系列のY値が進行するにつれて増大する付加的な定数項がある点が異なります。\n",
    "\n",
    "もちろん、ARIMAモデルを適合させる方法は他にもたくさんあります。そのため、複数のモデルを計算し、比較して、どのモデルがデータに最もよく適合するかを確認することがよくあります。これらはすべて一次モデルであり、線形プロセスをマッピングすることを意味します。二次プロセスをマッピングする2次モデルと、より複雑なプロセスをマッピングする上位モデルがあります。\n",
    "\n",
    "## ARIMAモデルの比較\n",
    "通常、複数のARIMAモデルをデータに適合させ、相互に比較することで、どの資産が時系列データに見られるパターンを予測しているかを見つけられます。ARIMAモデルの精度を評価するための重要な指標は次の3つです。\n",
    "\n",
    "1. **Akaikeの情報基準またはAIC**。これは、回帰モデルの予測子の選択に広く使用されており、ARIMAモデルの次数の決定にも役立ちます。AICは、モデルの適合性とモデルの単純さないし倹約性の両方を単一の統計情報で定量化します。AICスコアが低いほど良いため、スコアが低いモデルを好みます。AICはより単純なモデルを優先し、より複雑なモデルは、その精度がより単純なモデルとほぼ同じである限り、より高いスコアを獲得します。また、単にサンプル・サイズに小さな修正を加えた修正済みAICやAICCもあります。\n",
    "2. **ベイズ情報基準（BIC）**。これは、AICよりも多くの複雑さにペナルティーを与えるモデル選択のもう1つの基準です。AICと同様に、BICの低いモデルは、一般的にスコアの高いモデルよりも優先されます。モデルが長期予測に使用される場合は、BICの方が適している可能性がありますが、短期予測にはAICの方が適しているということかもしれません。\n",
    "3. **シグマ二乗またはsigma2値**は、モデル残差の分散です。シグマは、仮想プロセスの不安定性を表します。揮発性が高いデータにもかかわらずシグマ二乗スコアが非常に低い場合や、逆に非揮発性データであるがシグマ二乗スコアが高い場合は、モデルが実際のデータ生成プロセスをうまく捉えていないことを示しています。\n",
    "\n",
    "テスト・データ・セットを留保した場合は、異なる予測間隔のRMSEなどの精度メトリクスを比較することもできます。ARIMAモデルは、将来の単一の時間ステップまたは一度に複数のステップの値を予測できます。\n",
    "\n",
    "## ARIMAのバリエーション\n",
    "ARIMAモデルの構成と比較に対するもう1つのアプローチは、自動化された構成タスクをARIMAモデルの生成と比較に適用するAuto-ARIMAを使用することです。最適なモデルを得るには、複数の方法があります。アルゴリズムは複数のモデルを生成し、AICcと最尤推定の誤差を最小化してARIMAモデルを得ようとします。\n",
    "\n",
    "**季節性自己回帰統合移動平均、SARIMAまたは季節性ARIMA**は、季節的要素を含む時系列データをサポートするARIMAの拡張版です。そのために、系列の季節成分の自己回帰、差分、移動平均を指定する3つの新しいハイパーパラメーターと、季節性の期間のパラメーターを追加します。SARIMAモデルは通常、SARIMA((p,d,q),(P,D,Q))と表現され、小文字は時系列の非季節性成分を示し、大文字は季節性成分を示します。\n",
    "\n",
    "**ベクトル自己回帰モデル（またはVARモデル）**は、多変量の時系列に使用されます。これらは、各変数がそれ自体の過去の遅延と他の変数の過去の遅延の線形関数になるように構成されています。\n",
    "\n",
    "ARIMAモデルは、時系列データを分析して過去のプロセスを理解したり、時系列の将来の値を予測したりするための強力なツールです。ARIMAモデルは、自己回帰モデルと移動平均モデルを組み合わせて、予測者にさまざまな時系列データを使用できる高度にパラメーター化可能なツールを提供します。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}